{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa401e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install mediapipe opencv-python numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb28e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "mp_face = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "\n",
    "def crop_face(image_path, output_path, size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not read {image_path}\")\n",
    "        return\n",
    "    h, w, _ = img.shape\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(img_rgb)\n",
    "    if not results.multi_face_landmarks:\n",
    "        print(f\"No face detected in {os.path.basename(image_path)}\")\n",
    "        return\n",
    "\n",
    "    face_landmarks = results.multi_face_landmarks[0]\n",
    "    xs = [lm.x * w for lm in face_landmarks.landmark]\n",
    "    ys = [lm.y * h for lm in face_landmarks.landmark]\n",
    "\n",
    "    x_min, x_max = int(min(xs)), int(max(xs))\n",
    "    y_min, y_max = int(min(ys)), int(max(ys))\n",
    "\n",
    "    # tighten vertically to remove hair\n",
    "    y_min += int(0.1 * (y_max - y_min))\n",
    "    y_max -= int(0.05 * (y_max - y_min))\n",
    "\n",
    "    face_crop = img[y_min:y_max, x_min:x_max]\n",
    "    if face_crop.size == 0:\n",
    "        print(f\"Invalid crop for {os.path.basename(image_path)}\")\n",
    "        return\n",
    "\n",
    "    face_resized = cv2.resize(face_crop, size)\n",
    "    cv2.imwrite(output_path, face_resized)\n",
    "\n",
    "//we are using drive link to upload raw images and get the output-a folder of output named cropped images is stored in repo\n",
    "\n",
    "input_folder = \"/content/drive/MyDrive/datasets/victims\"   \n",
    "output_folder = \"/content/drive/MyDrive/cropped_faces\"\n",
    "zip_path = \"/content/drive/MyDrive/cropped_faces.zip\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        input_path = os.path.join(input_folder, file)\n",
    "        output_path = os.path.join(output_folder, f\"cropped_{file}\")\n",
    "        crop_face(input_path, output_path)\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    for file in os.listdir(output_folder):\n",
    "        zipf.write(os.path.join(output_folder, file),\n",
    "                   arcname=file,\n",
    "                   compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "print(f\" All cropped faces zipped successfully at: {zip_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
